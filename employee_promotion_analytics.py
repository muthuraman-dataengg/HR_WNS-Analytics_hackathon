# -*- coding: utf-8 -*-
"""Employee_Promotion_Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O9UBYNHyeo4-nuFpPd3m2t5_36UJ2hh0
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

from sklearn.model_selection import train_test_split,RandomizedSearchCV,cross_val_score
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder, LabelEncoder,StandardScaler

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression

from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.feature_selection import chi2

from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.compose import ColumnTransformer

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score

train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")
submission = pd.read_csv('sample_submission.csv')

train.rename(columns={'KPIs_met >80%': 'KPIs_met'}, inplace=True)
test.rename(columns={'KPIs_met >80%': 'KPIs_met'}, inplace=True)

train['is_promoted'].value_counts()

train.isna().sum()

for df in [train,test]:
  df['education'] = df['education'].fillna(df['education'].mode()[0])
  df['previous_year_rating'] = df['previous_year_rating'].fillna(df['previous_year_rating'].median())

train.head(4)

cat_num_cols_lst = train.select_dtypes(exclude=np.number).columns.tolist()
cat_num_cols_lst

num_cols_lst = train.drop(columns='employee_id').select_dtypes(include=np.number).columns.tolist()
num_cols_lst

# Calculate correlation and plot
train[num_cols_lst].corr()['is_promoted'].drop('is_promoted').sort_values(ascending=False).plot(kind='bar')

plt.figure(figsize=(20,10))
sns.heatmap(train[num_cols_lst].corr(), cmap="coolwarm",annot=True)

ign_cols_lst = ['length_of_service','no_of_trainings','age','is_promoted']
#ign_cols_lst = ['is_promoted']
num_cols = [item for item in num_cols_lst if item not in ign_cols_lst]
num_cols
#cat_cols = ['region']

X = train[num_cols+cat_num_cols_lst]
y = train['is_promoted']
X

train_X,test_X,train_y,test_y = train_test_split(X,y,test_size=.30,random_state=42)

numerical_transformer = Pipeline(
    steps = [
        ('imputer',SimpleImputer(strategy='mean')),
        ('scaler',StandardScaler())
    ]
)

categorical_transformer = Pipeline(
    steps = [
        ('imputer',SimpleImputer(strategy='most_frequent')),
        ('onehot',OneHotEncoder(handle_unknown='ignore'))
    ]
)

preprocess = ColumnTransformer(
    transformers = [
        ('num',numerical_transformer,num_cols),
        ('cat',categorical_transformer,cat_num_cols_lst)
    ]
)

model_process = Pipeline(
    steps = [
        ('preprocess',preprocess),
        ('model',LogisticRegression())
    ]
)

model_process.fit(train_X, train_y)

model_process = Pipeline(
    steps = [
        ('preprocess',preprocess),
        ('model',DecisionTreeClassifier())
    ]
)

model_process.fit(train_X, train_y)

train_pred = model_process.predict(train_X)
test_pred = model_process.predict(test_X)

print(accuracy_score(train_y, train_pred))
print(accuracy_score(test_y, test_pred))

print(classification_report(train_y, train_pred))
print(classification_report(test_y, test_pred))

test_logreg_av = test.drop(columns='employee_id')

test_logreg_pred_av = model_process.predict(test_logreg_av)

test_dt_av = test.drop(columns='employee_id')

test_dt_pred_av = model_process.predict(test_dt_av)
test_dt_pred_av

submission['is_promoted'] = test_logreg_pred_av
submission.to_csv('submission_Analyticvidhya_logreg.csv', index = False)

models_to_evaluate = [
    ['LogisticRegression', LogisticRegression()],
    ['DecisionTreeClassifier', DecisionTreeClassifier()],
    ['RandomForestClassifier', RandomForestClassifier()],
    ['AdaBoostClassifier', AdaBoostClassifier()]
]

for name, model_instance in models_to_evaluate:
    print(f"\nEvaluating {name}...")
    # Create a pipeline for each model that includes the preprocessing step
    full_pipeline = Pipeline(steps=[
        ('preprocess', preprocess),
        ('classifier', model_instance)
    ])

    full_pipeline.fit(train_X, train_y)
    prediction = full_pipeline.predict(test_X)
    print(f"{name} Accuracy: {accuracy_score(test_y, prediction)}")

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

from tokenize import Decnumber
param1 = [
    {
        'model': [LogisticRegression()],
        'model__penalty': ['l2',None,'l1','elasticnet'],
        'model__C': [0.5,3]
    },
    {
        'model': [DecisionTreeClassifier()],
        'model__max_depth': [3,5]
    }

]

grid_1 = GridSearchCV(estimator = model_process,param_grid=param1,cv=2,scoring='roc_auc')

from imblearn.over_sampling import RandomOverSampler

over_sampling = RandomOverSampler(sampling_strategy='minority')

train_X_os,train_y_os = over_sampling.fit_resample(train_X,train_y)

grid_1.fit(train_X_os, train_y_os)

res_df_1 = pd.DataFrame(grid_1.cv_results_)

pd.set_option('display.max_colwidth', 1000)
res_df_1[['param_model','params','mean_test_score','rank_test_score']]

def model_train_cal_eval(train_X,train_y,val_X,val_y,model_pipeline):
  predicted_train_tgt = model_pipeline.predict(train_X)
  predicted_val_tgt = model_pipeline.predict(val_X)

  print('Train Score:',roc_auc_score(train_y,predicted_train_tgt))
  print('Val Score:',roc_auc_score(val_y,predicted_val_tgt))

new_model = grid_1.best_estimator_
submission_2 = pd.read_csv('sample_submission.csv')
model_train_cal_eval(train_X_os, train_y_os, test_X, test_y, new_model)

submission_2['is_promoted'] = new_model.predict_proba(test[num_cols + cat_num_cols_lst])[:,1]
submission_2['is_promoted'] = (submission_2['is_promoted'] > 0.5).astype(int)
submission_2.to_csv('sub2_grid_os.csv',index=False)

import joblib
joblib.dump(new_model,'jobchg_pipeline_model.pkl')